{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Here we will be focusing more on the cnmf part and its main functions <h1>\n",
    "<img src='docs/img/cnmf1.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes when changed\n",
    "        get_ipython().magic(u'load_ext autoreload')\n",
    "        get_ipython().magic(u'autoreload 2')\n",
    "except NameError:       \n",
    "    print('Not IPYTHON')    \n",
    "    pass\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.sparse import coo_matrix\n",
    "import psutil\n",
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "from ipyparallel import Client\n",
    "import pylab as pl\n",
    "import caiman as cm\n",
    "from caiman.components_evaluation import evaluate_components\n",
    "from caiman.utils.visualization import plot_contours,view_patches_bar,nb_plot_contour,nb_view_patches\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "import caiman.source_extraction.cnmf as cnmf\n",
    "from caiman.utils.utils import download_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import bokeh.plotting as bp\n",
    "import bokeh.plotting as bpl\n",
    "try:\n",
    "       from bokeh.io import vform, hplot\n",
    "except:\n",
    "       # newer version of bokeh does not use vform & hplot, instead uses column & row\n",
    "       from bokeh.layouts import column as vform\n",
    "       from bokeh.layouts import row as hplot\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Slider\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cmap\n",
    "import numpy as np\n",
    "\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using the workload manager SLURM </h1> \n",
    "to have an extensive use of the machine. \n",
    "\n",
    "<p> we want to operate this the faster possible. Thanks to the segmentation of the video in patches we can parallelize ou algorithm. We are using python integrated methods to get this parallelization to work on one machine as well as on clusters of machines </p>\n",
    "\n",
    "<table> <tr> <td> This is to be used when working with a cluster of machines :  </td>\n",
    " <td>This will put dispatch and manage the workload gave by the algorithm : </td> </tr>\n",
    "<tr> <td><img src=\"docs/img/Dockerfile.gif\"/> \n",
    "<td> <img src=\"docs/img/node.gif\" /> </td> </tr>\n",
    "<p> learn more : <em> https://slurm.schedmd.com/overview.html </em> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frame rate in Hz\n",
    "final_frate=10 \n",
    "#backend='SLURM'\n",
    "backend='local'\n",
    "if backend == 'SLURM':\n",
    "    n_processes = np.int(os.environ.get('SLURM_NPROCS'))\n",
    "else:\n",
    "    # roughly number of cores on your machine minus 1\n",
    "    n_processes = np.maximum(np.int(psutil.cpu_count()),1) \n",
    "print('using ' + str(n_processes) + ' processes')\n",
    "#%% start cluster for efficient computation\n",
    "single_thread=False\n",
    "\n",
    "if single_thread:\n",
    "    dview=None\n",
    "else:    \n",
    "    try:\n",
    "        c.close()\n",
    "    except:\n",
    "        print('C was not existing, creating one')\n",
    "    print(\"Stopping  cluster to avoid unnencessary use of memory....\")\n",
    "    sys.stdout.flush()  \n",
    "    if backend == 'SLURM':\n",
    "        try:\n",
    "            cm.stop_server(is_slurm=True)\n",
    "        except:\n",
    "            print('Nothing to stop')\n",
    "        slurm_script='/mnt/xfs1/home/agiovann/SOFTWARE/Constrained_NMF/SLURM/slurmStart.sh'\n",
    "        cm.start_server(slurm_script=slurm_script)\n",
    "        pdir, profile = os.environ['IPPPDIR'], os.environ['IPPPROFILE']\n",
    "        c = Client(ipython_dir=pdir, profile=profile)        \n",
    "    else:\n",
    "        cm.stop_server()\n",
    "        cm.start_server()        \n",
    "        c=Client()\n",
    "\n",
    "    print('Using '+ str(len(c)) + ' processes')\n",
    "    dview=c[:len(c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see here that the number of processes are the number of core your computer possess. <br/> Your computer can be seen as a node that possess X cores </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Memory mapping files in F order</h1>\n",
    "<p> see : http://localhost:8888/notebooks/CaImAn/demo_caiman_pipeline.ipynb </p>\n",
    "<p> We want the parallel processes to access and our video matrix without having it in memory and duplicating it, as explained already on the demo_pipeline notebook </p>\n",
    "<img src=\"docs/img/Fordermmap.png\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% FOR LOADING ALL TIFF FILES IN A FILE AND SAVING THEM ON A SINGLE MEMORY MAPPABLE FILE\n",
    "fnames=['demoMovieJ.tif']\n",
    "base_folder='./example_movies/' # folder containing the demo files\n",
    "# %% download movie if not there                                                                                                                                                                                \n",
    "if fnames[0] in ['Sue_2x_3000_40_-46.tif','demoMovieJ.tif']:\n",
    "    download_demo(fnames[0])\n",
    "    fnames = [os.path.join('example_movies',fnames[0])]\n",
    "m_orig = cm.load_movie_chain(fnames[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "downsample_factor=1 # use .2 or .1 if file is large and you want a quick answer\n",
    "final_frate=final_frate*downsample_factor\n",
    "name_new=cm.save_memmap_each(fnames\n",
    "        , dview=dview,base_name='Yr', resize_fact=(1, 1, downsample_factor)\n",
    "        , remove_init=0,idx_xy=None )\n",
    "name_new.sort()\n",
    "fname_new=cm.save_memmap_join(name_new,base_name='Yr', n_chunks=12, dview=dview)\n",
    "print(fnames)\n",
    "print(fname_new)\n",
    "print (\"\\n we can see we are loading the file (line1) into a memorymapped object (line2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>the correlation image </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Yr,dims,T=cm.load_memmap(fname_new)\n",
    "Y=np.reshape(Yr,dims+(T,),order='F')\n",
    "#%% visualize correlation image\n",
    "Cn = cm.local_correlations(Y)\n",
    "pl.imshow(Cn,cmap='gray') \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CNMFSetParms define Dictionaries of CNMF parameters.\n",
    " Any parameter that is not set get a default value specified.\n",
    " \n",
    "     each dictionnary is used by different part of the CNMF process : \n",
    " - init_paramters\n",
    " - pre_processing_parameters\n",
    " - patch_parameters\n",
    " - spatial_parameters\n",
    " - temporal_parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K=30 # number of neurons expected per patch\n",
    "gSig=[6,6] # expected half size of neurons\n",
    "merge_thresh=0.8 # merging threshold, max correlation allowed\n",
    "p=2 #order of the autoregressive system\n",
    "options = cnmf.utilities.CNMFSetParms(Y\n",
    "        ,n_processes,p=p,gSig=gSig,K=K,ssub=2,tsub=2, normalize_init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing of the datas and initialization of the components </h2>\n",
    "<ul><li> here, we compute the mean of the noise spectral density </li>\n",
    "<li> then, we initialize each component (components that have been spatially filter using a gaussian kernel) with a greedy algorithm </li>\n",
    "<li> we then operate a rank1 NMF on those ROIs using the HALS algorithm</li></ul>\n",
    "<p> see More : NMF AND ROI :http://www.cell.com/neuron/fulltext/S0896-6273(15)01084-3<br\\></p>\n",
    "Simultaneous Denoising, Deconvolution, and Demixing of Calcium Imaging Data by Eftychios A. Pnevmatikakis & al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Yr,sn,g,psx = cnmf.pre_processing.preprocess_data(Yr\n",
    "            ,dview=dview\n",
    "            ,n_pixels_per_process=100,  noise_range = [0.25,0.5]\n",
    "            ,noise_method = 'logmexp', compute_g=False,  p = 2,\n",
    "             lags = 5, include_noise = False, pixels = None\n",
    "            ,max_num_samples_fft=3000, check_nan = True)\n",
    "\n",
    "Ain, Cin, b_in, f_in, center=cnmf.initialization.initialize_components(Y\n",
    "            ,K=30, gSig=[5, 5], gSiz=None, ssub=1, tsub=1, nIter=5, maxIter=5, nb=1\n",
    "            , use_hals=False, normalize_init=True, img=None, method='greedy_roi'\n",
    "            , max_iter_snmf=500, alpha_snmf=10e2, sigma_smooth_snmf=(.5, .5, .5)\n",
    "            , perc_baseline_snmf=20)\n",
    "p1=nb_plot_contour(Cn,Ain,dims[0],dims[1],thr=0.9,face_color=None\n",
    "                    , line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> HALS </h2>\n",
    "we want to minimize\n",
    "<img src=docs/img/hals1.png width=300px/>\n",
    "updating parameters\n",
    "<img src=docs/img/hals2.png width=300px />\n",
    "<p>HALS :  (Keigo Kimura et al.) http://proceedings.mlr.press/v39/kimura14.pdf</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ain, Cin, b_in, f_in = cnmf.initialization.hals(Y, Ain, Cin, b_in, f_in, maxIter=5)\n",
    "p1=nb_plot_contour(Cn,Ain,dims[0],dims[1],thr=0.9,face_color=None\n",
    "                    , line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CNMF process </h1>\n",
    "\n",
    "*** We are considering the video as a matrix called Y of dimension height x widht x frames ***\n",
    "\n",
    "    we now want to find A, C and B such that Y = A x C + B\n",
    "    \n",
    "    B being the Background, composed of its spatial b and temporal f component\n",
    "    A being the spatial component of the neurons (also seen as their shape)\n",
    "    C being the temporal component of the neurons (also seen as their calcium activity or traces)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Update spatial </h2>\n",
    "\n",
    "** will consider C as fixed and try to update A. **\n",
    "\n",
    "    the process will be the following : \n",
    "    \n",
    "   - intialization of each parameters \n",
    "   - testing of the input values\n",
    "    \n",
    "   - finding relevant pixels in that should belong to the neuron using either an iterative structure or an ellipse to look around the center of mass of the neuron ( cm found in the initialization )\n",
    "     - this will be define a first shape of the neuron \n",
    "     - /!\\ pixels are usually unlinked\n",
    "            \n",
    "   - computing the distance indicator (a map of the distances of each relevant pixels to the center of mass of the neuron)\n",
    "   \n",
    "   -  memory mapping the matrices C and Y (info before)\n",
    "   \n",
    "   - updating the components in parallel : \n",
    "     - using ipyparralel\n",
    "     - solving this problem for each pixel of the component\n",
    "          $$ arg\\min_{A_i,B_i}\\sum A_i $$\n",
    "       subject to\n",
    "          $$|| Y_i - A_i\\times C + b_i\\times f || <= std_{noise}(i)\\times \\sqrt(T)$$\n",
    "     - using the lasso lars method from scikit learn toolbox\n",
    "         https://en.wikipedia.org/wiki/Least-angle_regression, <br/>\n",
    "         https://en.wikipedia.org/wiki/Lasso_(statistics), <br/>\n",
    "         http://scikit-learn.org/stable/modules/linear_model.html#lars-lasso\n",
    "   \n",
    "   \n",
    "   - then, the newly refined components are thresholded (the C of the CNMF, one of the constrained here is that the matrix needs to be sparse) :\n",
    "   \n",
    "     - first by applicating a median filtering  https://en.wikipedia.org/wiki/Median_filter\n",
    "     - then by thresholding using a normalized user defined value \n",
    "     - continuing with a morphological closing of the components, using openCv functions https://www.mathworks.com/help/images/ref/imclose.html (the matlab version)\n",
    "     - we remove the unconnected pixels (we keep the large connected components )\n",
    "     \n",
    "     \n",
    "   - finnaly we compute the residuals (also called the background) which is computed as B=Y-AC\n",
    "   \n",
    "       \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options['spatial_params']['n_pixels_per_process'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A,b,Cin,f_in = cnmf.spatial.update_spatial_components(Yr, Cin, f_in, Ain, sn=sn, dview=dview,**options['spatial_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p1=nb_plot_contour(Cn,A.todense(),dims[0],dims[1],thr=0.9,face_color=None,\n",
    "                   line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Update temporal </h2>\n",
    "\n",
    "** Will consider A as fixed and try to update C. **\n",
    "\n",
    "    the process will be the following : \n",
    "    \n",
    "   - Intialization of each parameters \n",
    "   - Testing of the input values\n",
    "    \n",
    "   - Generating residuals s.t. $$Yres_A = YA - (A^T AC)^T$$\n",
    "   \n",
    "   - Creating groups of components that can be processed in parallel\n",
    "     - Ones that are composed of not overlapping components\n",
    "     - Using a simple greedy method\n",
    "     \n",
    "   - Updating Calcium traces ( C ) \n",
    "     - Using Oasis. which will deconvolve the spikes of each neurons from the Calcium traces matrix C.  <br\\><br\\> learn more : (Friedrich & al) http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005423\n",
    "     see the demo here : https://github.com/j-friedrich/OASIS/blob/master/examples/Demo.ipynb\n",
    "       - To infer the true shape of the calcium traces using an autoregressive framework\n",
    "       - To infer the most likely spike train ( also called particular events). It will find the probability of a spike train according to the mean and std of the trace. \n",
    "            - If it is superior to a threshold it will be defined as a particular event/neural spike\n",
    "      \n",
    "            -  This will give us a matrix which is itself constrained ( C from CNMF ) \n",
    "     - This is done in parallel using ipyparallel. \n",
    "   - We finally update the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options['temporal_params']['block_size'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "options['temporal_params']['p'] = 0 # fast updating without deconvolution\n",
    "C,A,b,f,S,bl,c1,neurons_sn,g,YrA,lam = cnmf.temporal.update_temporal_components(\n",
    "    Yr,A,b,Cin,f_in,bl=None,c1=None,sn=None,g=None,**options['temporal_params'])  \n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Merging components </h2>\n",
    "\n",
    "**merge the components that overlaps and have a high temporal correlation **\n",
    "\n",
    "    the process will be the following : \n",
    "    \n",
    "   - intialization of each parameters \n",
    "   - testing of the input values\n",
    "   \n",
    "   - find a graph of overlapping components\n",
    "     - we look for connected ones\n",
    "     - we keep the one that are \"connected enough\" (above a threshold)\n",
    "     \n",
    "    \n",
    "   - On Each groups : \n",
    "     - We normalize the components to be able to compare them\n",
    "     - We sum them together\n",
    "     - we process a rank one NMF\n",
    "     - we compute the traces (deconvolution)\n",
    "     - We replace the neurons by the merged one\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_m,C_m,nr_m,merged_ROIs,S_m,bl_m,c1_m,sn_m,g_m=cnmf.merging.merge_components(\n",
    "    Yr,A,b,C,f,S,sn,options['temporal_params'], options['spatial_params'],\n",
    "    dview=dview, bl=bl, c1=c1, sn=neurons_sn, g=g, thr=merge_thresh,\n",
    "    mx=50, fast_merge = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A refining step\n",
    "refine spatial and temporal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A2,b2,C2,f = cnmf.spatial.update_spatial_components(Yr, C_m, f, A_m,\n",
    "                                sn=sn,dview=dview, **options['spatial_params'])\n",
    "options['temporal_params']['p'] = p # set it back to perform full deconvolution\n",
    "\n",
    "C2,A2,b2,f2,S2,bl2,c12,neurons_sn2,g21,YrA, lam = cnmf.temporal.update_temporal_components(\n",
    "    Yr,A2,b2,C2,f,dview=dview, bl=None,c1=None,sn=None,g=None,**options['temporal_params'])\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DISCARD LOW QUALITY COMPONENT </h1>\n",
    "<p> The patch dubdivision creates several spurious components that are not neurons </p>\n",
    "<p>We select the components according to criteria examining spatial and temporal components</p>\n",
    "<img src=\"docs/img/evaluationcomponent.png\"/>\n",
    "\n",
    "<p> Temporal components, for each trace: </p>\n",
    "\n",
    "<li>  compute the robust mode, corresponding to the baseline value</li>\n",
    "<li> use the values under the mode to estimate noise variance</li>\n",
    "<li> compute the probability of having large transients  given the noise distribution estimated </li>\n",
    "<li> Threshold on this probability s.t. some of the component are discarded because lacking large enough positive transients </li>\n",
    "\n",
    "<p> Spatial components, for each components: </p>\n",
    "\n",
    "<li> average the frames in the moveie where the neurons is active (from temporal component), this provides a nice image of the neuron</li>\n",
    "<li> compare this image with the corresponding spatial component (Person's correlation coefficient)</li>\n",
    "<li> threshold the correlation coefficient  </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#evaluation\n",
    "fitness_raw, fitness_delta, erfc_raw,erfc_delta, r_values, significant_samples = evaluate_components(Y, C2+YrA, A2, C2, b2, f2, final_frate,\n",
    "                                          remove_baseline=True,N=5, robust_std=False,\n",
    "                                          Athresh=0.1, Npeaks=10,  thresh_C=0.3)\n",
    "#different thresholding ( needs to pass at least one of them )\n",
    "traces = C2 + YrA\n",
    "idx_components_r=np.where(r_values>=.6)[0]\n",
    "idx_components_raw=np.where(fitness_raw<-60)[0]        \n",
    "idx_components_delta=np.where(fitness_delta<-20)[0]   \n",
    "\n",
    "#merging to have all that have passed at least one threshold.\n",
    "idx_components=np.union1d(idx_components_r,idx_components_raw)\n",
    "idx_components=np.union1d(idx_components,idx_components_delta) \n",
    "#finding the bad components\n",
    "idx_components_bad=np.setdiff1d(range(len(traces)),idx_components)\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(' ***** ')\n",
    "print(len(traces))\n",
    "print(len(idx_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fg=pl.figure(figsize=(12,20))\n",
    "pl.subplot(1,2,1)\n",
    "crd = plot_contours(A2.tocsc()[:,idx_components],Cn,thr=0.9)\n",
    "\n",
    "pl.subplot(1,2,2)\n",
    "crd = plot_contours(A2.tocsc()[:,idx_components_bad],Cn,thr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p2=nb_plot_contour(Cn,A2.tocsc()[:,idx_components].todense(),dims[0],dims[1],thr=0.9,face_color='purple', line_color='black',alpha=0.3,line_width=2)\n",
    "bpl.show(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accepted components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discard_traces_fluo=nb_view_patches(Yr,A2.tocsc()[:,idx_components],C2[idx_components],b2,f2,dims[0],dims[1],thr = 0.8,image_neurons=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discarded components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discard_traces_fluo=nb_view_patches(Yr,A2.tocsc()[:,idx_components_bad],C2[idx_components_bad],b2,f2,dims[0],dims[1],thr = 0.8,image_neurons=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm.stop_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
