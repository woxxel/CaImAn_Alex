{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volumetric data processing\n",
    "This is a simple demo on toy 3d data for source extraction and deconvolution using CaImAn.\n",
    "For more information check demo_pipeline.ipynb which performs the complete pipeline for\n",
    "2d two photon imaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "\n",
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    print(1)\n",
    "except:\n",
    "    print('NOT IPYTHON')\n",
    "\n",
    "from ipyparallel import Client\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import sys\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.visualization import nb_view_patches3d\n",
    "import caiman.source_extraction.cnmf as cnmf\n",
    "from caiman.components_evaluation import evaluate_components, estimate_components_quality_auto\n",
    "from caiman.cluster import setup_cluster\n",
    "from caiman.paths import caiman_datadir\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the cluster if one exists\n",
    "n_processes = psutil.cpu_count()\n",
    "print('using ' + str(n_processes) + ' processes')\n",
    "print(\"Stopping  cluster to avoid unnencessary use of memory....\")\n",
    "sys.stdout.flush()  \n",
    "cm.stop_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(p=1, noise=1., T=256, framerate=30, firerate=2., plot=False):\n",
    "    if p == 2:\n",
    "        gamma = np.array([1.5, -.55])\n",
    "    elif p == 1:\n",
    "        gamma = np.array([.9])\n",
    "    else:\n",
    "        raise\n",
    "    dims = (30, 40, 50)  # size of image\n",
    "    sig = (2, 2, 2)  # neurons size\n",
    "    bkgrd = 10\n",
    "    N = 20  # number of neurons\n",
    "    np.random.seed(7)\n",
    "    centers = np.asarray([[np.random.randint(5, x - 5)\n",
    "                           for x in dims] for i in range(N)])\n",
    "    Yr = np.zeros(dims + (T,), dtype=np.float32)\n",
    "    trueSpikes = np.random.rand(N, T) < firerate / float(framerate)\n",
    "    trueSpikes[:, 0] = 0\n",
    "    truth = trueSpikes.astype(np.float32)\n",
    "    for i in range(2, T):\n",
    "        if p == 2:\n",
    "            truth[:, i] += gamma[0] * truth[:, i - 1] + gamma[1] * truth[:, i - 2]\n",
    "        else:\n",
    "            truth[:, i] += gamma[0] * truth[:, i - 1]\n",
    "    for i in range(N):\n",
    "        Yr[centers[i, 0], centers[i, 1], centers[i, 2]] = truth[i]\n",
    "    tmp = np.zeros(dims)\n",
    "    tmp[15, 20, 25] = 1.\n",
    "    z = np.linalg.norm(gaussian_filter(tmp, sig).ravel())\n",
    "    Yr = bkgrd + noise * np.random.randn(*(dims + (T,))) + 10 * gaussian_filter(Yr, sig + (0,)) / z\n",
    "    d1, d2, d3, T = Yr.shape\n",
    "    Yr = np.reshape(Yr, (d1 * d2 * d3, T), order='F').astype(np.float32)\n",
    "\n",
    "    if plot:\n",
    "        Y = np.reshape(Yr, (d1, d2, d3, T), order='F')\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        plt.plot(truth.T)\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        for c in centers:\n",
    "            plt.plot(Y[c[0], c[1], c[2]])\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.subplot(131)\n",
    "        plt.scatter(*centers.T[::-1], c='g')\n",
    "        plt.imshow(Y.max(0).max(-1), cmap='hot')\n",
    "        plt.title('Max.proj. x & t')\n",
    "        plt.subplot(132)\n",
    "        plt.scatter(*centers.T[[2, 0, 1]], c='g')\n",
    "        plt.imshow(Y.max(1).max(-1), cmap='hot')\n",
    "        plt.title('Max.proj. y & t')\n",
    "        plt.subplot(133)\n",
    "        plt.scatter(*centers.T[[1, 0, 2]], c='g')\n",
    "        plt.imshow(Y.max(2).max(-1), cmap='hot')\n",
    "        plt.title('Max.proj. z & t')\n",
    "        plt.show()\n",
    "\n",
    "    return Yr, truth, trueSpikes, centers, dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation and memory mapping\n",
    "- create a toy 3d dataset if it doesn't exist.\n",
    "- perform memory mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "#%% SAVING TIFF FILE ON A SINGLE MEMORY MAPPABLE FILE\n",
    "demo_filename = os.path.join(caiman_datadir(), 'example_movies', 'demoMovie3D.tif')\n",
    "try:\n",
    "    fname_new = cm.save_memmap([demo_filename], base_name='Yr', is_3D=True, order='C')\n",
    "except:  # %% create 3d tiff file if not yet existent\n",
    "    from skimage.external.tifffile import imsave\n",
    "    Yr, truth, trueSpikes, centers, dims = gen_data(p=2)\n",
    "    data = np.transpose(Yr.reshape(dims + (-1,), order='F'), [3, 0, 1, 2])\n",
    "    imsave(demo_filename, data)\n",
    "    fname_new = cm.save_memmap([demo_filename], base_name='Yr', is_3D=True, order='C')\n",
    "\n",
    "print(fname_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load memory mapped file and show a max-projection of the correlation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "Y = np.reshape(Yr, dims + (T,), order='F')\n",
    "Cn = cm.local_correlations(Y)\n",
    "plt.imshow(Cn.max(0) if len(Cn.shape) == 3 else Cn, cmap='gray',\n",
    "           vmin=np.percentile(Cn, 1), vmax=np.percentile(Cn, 99))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF\n",
    "### If data is small enough use a single patch approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "K = 20  # number of neurons expected per patch\n",
    "gSig = [2, 2, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# START CLUSTER\n",
    "c, dview, n_processes = setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize CNMF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "cnm = cnmf.CNMF(n_processes, method_init='greedy_roi', k=K, gSig=gSig, merge_thresh=merge_thresh,\n",
    "                p=p, dview=dview, Ain=None, method_deconvolution='oasis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# FIT\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')    # reshape data in Python format (T x X x Y x Z)\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View components per plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.nb_view_components_3d(image_type='mean', dims=dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF\n",
    "### For larger data use a patch approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rf = (15, 15, 15)  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "stride = (10, 10, 10)  # amounpl.it of overlap between the patches in pixels\n",
    "K = 12  # number of neurons expected per patch\n",
    "gSig = [2, 2, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system\n",
    "save_results = False\n",
    "#%% RUN ALGORITHM ON PATCHES\n",
    "init_method = 'greedy_roi'\n",
    "alpha_snmf = None  # 10e2  # this controls sparsity\n",
    "\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=0.8, p=p, dview=dview, Ain=None, rf=rf, stride=stride, memory_fact=1,\n",
    "                method_init=init_method, alpha_snmf=alpha_snmf, only_init_patch=True, gnb=1, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "\n",
    "print(('Number of components:' + str(cnm.estimates.A.shape[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "fr = 10 # approx final rate  (after eventual downsampling )\n",
    "decay_time = 1.  # length of typical transient in seconds \n",
    "use_cnn = False  # CNN classifier is designed for 2d (real) data\n",
    "min_SNR = 3      # accept components with that peak-SNR or higher\n",
    "rval_thr = 0.7   # accept components iwth speace correlation threshold or higher\n",
    "cnm.params.change_params(params_dict={'fr': fr,\n",
    "                                      'decay_time': decay_time,\n",
    "                                      'min_SNR': min_SNR,\n",
    "                                      'rval_thr': rval_thr,\n",
    "                                      'use_cnn': use_cnn})\n",
    "\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(('Keeping ' + str(len(cnm.estimates.idx_components)) +\n",
    "       ' and discarding  ' + str(len(cnm.estimates.idx_components_bad))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run seeded CNMF\n",
    "Now we re-run CNMF on the whole FOV seeded with the accepted components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RE-RUN seeded CNMF on accepted components\n",
    "cnm.params.set('temporal', {'p': p})\n",
    "cnm2 = cnm.refit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view components per layer\n",
    "cnm2.estimates.nb_view_components_3d(image_type='corr', dims=dims, Yr=Yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP CLUSTER\n",
    "cm.stop_server(dview=dview)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
